***

Ein Klassiker der Quantenmechanik der für ein qualitativ hochwertigeres Verständnis von dynamischen Systemen sorgt. Dafür fangen wir beim klassischen Beispiel an ein beliebiges Potential $V(x)$ zu betrachten, welches lokale Minima $x_{i}$ besitzt. Wir suchen uns eins aus, nennen es $x_{0}$, und stellen uns ein Teilchen vor, welches dort drinnen "sitzt". Dieses lenken wir ein wenig aus dieser Gleichgewichtsposition $x_{0}$ aus, um die Dynamik zu verstehen entwickeln wir das Potential $V(x)$:

$$
V(x)=V(x_{0})+V'(x_{0})(x-x_{0})+ \frac{1}{2}V''(x_{0})(x-x_{0})^{2}+\mathcal{O}([x-x_{0}]^{3})
$$

Die Krümmung im Minimum ist positiv, und dort verschwindet auch die Steigung. Durch geeignete Verschiebung des KOS können wir dazu die Konstante $V(x_{0})$ eliminieren

$$
V(x)=\frac{1}{2}V''(x_{0})(x-x_{0})^{2}+\mathcal{O}([x-x_{0}]^{3})
$$

Diese Näherung gilt für kleine Auslenkung, sodass die Terme $[x-x_{0}]^{3}$ und höher ansatzweise verschwinden. Wir erhalten den harmonischen Oszillator, mit Eigenfrequenz $\omega=\sqrt{ V''(x_{0}) /m }$. Wir bleiben dabei in einer Dimension, doch höherdimensionale harmonische Oszillator lassen sich auf dem gleichen Weg bilden.

Ähnlich lässt sich dieses Problem für ein QM Wellenpaket erstellen. Dabei beachten wir von Beginn an, dass aufgrund des Tunneleffekts ein Teil der WK Dichte um $x_{0}$ "verloren geht". Wir betrachten zuerst den Hamiltonoperator des harmonischen Oszillators:

$$
H=\frac{\hat{p}^{2}}{2m}+\frac{1}{2}m\omega^{2}\hat{x}^{2}
$$

Diesen erhalten wir durch das Korrespondenzprinzip aus der klassischen Hamiltonschen. Wie wir es schon so oft gemacht haben fällt ein Operator $a$ (kein Hut, da wir keine Verwechslungsgefahr mit anderen Variablen erzeugen werden) aus dem Himmel, der unser Problem vereinfachen wird. Dieser ist definiert als

$$
a:= \sqrt{ \frac{m\omega}{2\hbar} }\hat{x}+\frac{i}{\sqrt{ 2m\hbar \omega }}\hat{p}
$$

Der adjungierte Operator $a^{\dagger}$ dazu ist dann

$$
a^{\dagger}=\sqrt{ \frac{m\omega}{2\hbar} }\hat{x}-\frac{i}{\sqrt{ 2m\hbar \omega }}\hat{p}
$$

Dies tun wir natürlich nicht ohne Grund, sondern hilft enorm um später das Problem zu diskretisieren. Quantenzahlen existieren aber bisher nicht. Der Operator $a$ ist also nicht selbstadjungiert, dafür aber der Operator $\hat{N}=a^{\dagger}a$, der ausgeschrieben

$$
\begin{align}
\hat{N}&:=a^{\dagger}a \\
&=\left( \sqrt{ \frac{m\omega}{2\hbar} }\hat{x}-\frac{i}{\sqrt{ 2m\hbar \omega }}\hat{p} \right)\left( \sqrt{ \frac{m\omega}{2\hbar} }\hat{x}+\frac{i}{\sqrt{ 2m\hbar \omega }}\hat{p} \right) \\
&=\frac{m\omega}{2\hbar}\hat{x}^{2}+\frac{1}{2m\hbar \omega}\hat{p}^{2}+\frac{i}{2\hbar}[\hat{x},\hat{p}] \\
&=\frac{1}{\hbar \omega}H-\frac{1}{2}\mathbf{1}
\end{align}
$$

Wir sehen also, wir haben $a$ definiert, um den Hamiltonoperator $H$ neu zu schreiben:

$$
H=\hbar \omega\left( \hat{N}+\frac{1}{2} \right)=\hbar \omega\left( a^{\dagger}a+\frac{1}{2} \right)
$$

Wir reduzieren also das Problem darauf nicht die Eigenwerte von $H$, sondern von $\hat{N}$ zu finden, dessen Definition wir kennen. Als nächstes interessiert uns der Kommutator $[a,a^{\dagger}]$ den wir über [[5.1 Der Hilbertraum#^6cd6b4]] leicht schreiben können:

$$
[a,a^{\dagger}]=\frac{1}{2\hbar}(-i[\hat{x},\hat{p}]+i[\hat{p},\hat{x}])=\mathbf{1}
$$

Weiter wollen wir $[a,\hat{N}]$ und $[a^{\dagger},\hat{N}]$ berechnen aus zukünftigen Gründen. Wir erhalten:

$$
\begin{align}
[a,\hat{N}]&=[a,a^{\dagger}a]=[a,a^{\dagger}]a+a^{\dagger}[a,a]=a \\
[a^{\dagger},\hat{N}]&=[a^{\dagger},a^{\dagger}a]=[a^{\dagger},a^{\dagger}]a+a^{\dagger}[a^{\dagger},a]=-a^{\dagger}
\end{align}
$$

Nun werden wir uns dem EW Problem von $\hat{N}=\hat{N}^{\dagger}$ widmen, wobei wir fordern, dass es einen normierten EV $\ket{\varphi_{\nu}}$ von $\hat{N}$ zum Eigenwert $\nu \in \mathbb{R}$ gibt

$$
\hat{N}\ket{\varphi_{\nu}}=\nu \ket{\varphi_{\nu}}  
$$

Zusätzlich kreieren wir die Zustände

$$
\begin{align}
\ket{\varphi^{+}_{\nu}}&:=a^{\dagger}\ket{\varphi_{\nu}} \\
\ket{\varphi^{-}_{\nu}}&:=a\ket{\varphi_{\nu}} 
\end{align}
$$

Diese sind nicht normiert. Wir wollen nun zeigen, dass $\nu\geq 0$ ist, und später, dass sogar $\nu \in \mathbb{N}$ liegt. Daher haben wir uns die oberen Zustände definiert. Da $\ket{\varphi_{\nu}}$ normiert sein sollen, können wir $\nu$ mit $\braket{ \varphi_{\nu} | \varphi_{\nu} }$ multiplizieren, und von da aus weitermachen:

$$
\nu=\nu \braket{ \varphi_{\nu} | \varphi_{\nu} }=\bra{\varphi_{\nu}}\nu \ket{\varphi_{\nu}}=\bra{\varphi_{\nu}}\hat{N}\ket{\varphi_{\nu}}=\bra{\varphi_{\nu}}a^{\dagger}a\ket{\varphi_{\nu}}=\braket{ \varphi^{-}_{\nu} | \varphi^{-}_{\nu} }\geq 0        
$$

Wir erhalten das $\geq$ da nicht ausgeschlossen ist, dass $\ket{\varphi^{-}_{n}}$ der Nullvektor ist. Dies tun wir jedoch für $\ket{\varphi^{+}_{\nu}}$:

$$
\braket{ \varphi_{n}^{+} | \varphi_{n}^{+} }=\bra{\varphi_{\nu}}aa^{\dagger}\ket{\varphi_{\nu}}=\bra{\varphi_{\nu}}(\hat{N}+[a,a^{\dagger}])\ket{\varphi_{\nu}}=\bra{\varphi_{\nu}}(\hat{N}+\mathbf{1})\ket{\varphi_{\nu}}=\nu+1 >0
$$

Das bedeutet, dass $\ket{\varphi^{+}_{\nu}}$ ein Eigenvektor von $\hat{N}$ zum EW $\nu+1$ ist

$$
\hat{N}\ket{\varphi_{\nu}^{+}}=\hat{N}a^{\dagger}\ket{\varphi_{\nu}}=(a^{\dagger}\hat{N}-[a^{\dagger},\hat{N}])\ket{\varphi_{\nu}}=a^{\dagger}(\hat{N}+\mathbf{1})\ket{\varphi_{\nu}}=(\nu+1)\ket{\varphi^{+}_{\nu}}     
$$

$\ket{\varphi_{\nu}^{+}}$ Eigenwert wird also immer um eins größer als der ursprüngliche Eigenwert. Dadurch nennen wir $a^{\dagger}$ einen **Aufsteigeoperator**. Wir können also den Ket normieren und daraus einen EV zum Eigenwert $\nu+1$ machen und nennen ihn $\ket{\varphi_{\nu+1}}$. 

Wir kennen dadurch also sofort alle Eigenvektoren, indem wir immer wieder hintereinander mit $a^{\dagger}$ multiplizieren. So erhalten wir $\nu,\nu+1,\nu+2,\dots$ usw. also alle Eigenwerte.

Nehmen wir an, dass $\nu>0$ ist, dann wissen wir, dass $\ket{\varphi^{-}_{\nu}}$ nicht der Nullvektor sein kann. Auf ähnlichem Wege entdecken wir dann:

$$
\hat{N}\ket{\varphi^{-}_{\nu}}=\hat{N}a\ket{\varphi_{\nu}}=(a\hat{N}-[a,\hat{N}])\ket{\varphi_{\nu}}=a(\hat{N}-\mathbf{1})\ket{\varphi_{\nu}}=(\nu-1)\ket{\varphi_{\nu}^{-}}     
$$

Also ist $\ket{\varphi_{\nu}^{-}}$ ein EV zu $\hat{N}$ zum EW $\nu-1$, da aber $\nu\geq 0$ gelten darf, schließen wir daraus, dass dieser Eigenvektor nur für $\nu\geq 1$ entstehen kann. Nun normieren wir wieder den EV und erhalten den Eigenzustand $\ket{\varphi_{\nu-1}}$. Wir können also - in diesem Fall begrenzt - in Einserschritten **absteigen**. weshalb $a$ auch **Absteigeoperator** genannt wird. Das Bündel $a,a^{\dagger}$ wird **Leiteroperatoren** genannt (Oder auch **Erzeugungs- und Vernichtungsoperatoren**, klingt cooler).

Wir haben bis jetzt $\nu$ beliebig, aber $\nu\geq 0$ gewählt. Wir können diese *reelle* Zahl also als Summe von natürlicher Zahl $M\in \mathbb{N}_{0}$ und Dezimalzahl $\lambda \in[0,1)$ darstellen, also $\nu=M+\lambda$. Wir kennen dadurch, wie oft wir den Absteigeoperator $a$ anwenden dürfen, nämlich $M$ mal, bevor $\nu<0$ wird. Wir erhalten also alle Eigenwerte, zu gegebenen Starteigenwert $\nu$: $\nu-1,\nu-2,\nu-3,\dots, \nu-M=\lambda$. $\lambda \in[0,1)$ ist also auch ein Eigenwert von $\hat{N}$, und seinen nicht-normierten Eigenvektor können wir als $\ket{\varphi_{\nu}^{M}}:=a^{M}\ket{\varphi_{\nu}}$ schreiben. Würden wir nun noch einmal $a$ anwenden wollen, würden wir mit unserer $\nu-1$ Konvention unter Null treten, und das ist nicht erlaubt. Die Folge ist, dass $a \ket{\varphi_{\nu}^{M}}=0$ liefert, also den Nullvektor bildet (Die Argumentation ist etwas lasch, aber nur so können wir den negativen EW vermeiden). Multiplizieren wir $\bra{\varphi_{\nu}^{M}}a^{\dagger}$ von links hinzu, so erhalten wir

$$
\bra{\varphi_{\nu}^{M}}\underbrace{ a^{\dagger}a }_{ \hat{N} }\ket{\varphi_{\nu}^{M}}=\lambda \braket{ \varphi_{\nu}^{M} | \varphi_{\nu}^{M} }=0 
$$

Wir haben ausgeschlossen, dass $\ket{\varphi_{\nu}^{M}}$ der Nullvektor ist. Die Folge ist also, dass $\lambda=0$ gilt, was wiederum bedeutet, dass jedes $\nu=M$ ist, und daher immer eine natürliche Zahl $n\in \mathbb{N}_{0}$ ist!

Wir schreiben nun unsere $\ket{\varphi_{\nu}}$ um zu $\ket{n,i}$, das $i$ steht da, weil wir noch nicht wissen, ob gewisse Eigenwerte $n$ nicht entartet sind. Statt $\hat{N}\ket{\varphi_{\nu}}=\nu \ket{\varphi_{\nu}}$ schreiben wir also jetzt $\hat{N}\ket{n,i}=n\ket{n,i}$, für $H$ gilt darum:

$$
H\ket{n,i}=\hbar \omega\left( \hat{N}+\frac{1}{2} \right)\ket{n,i} =\hbar \omega\left( n+\frac{1}{2} \right)\ket{n,i}  
$$

Und damit können wir vieles schließen: Die Eigenzustände von $\hat{N}$ sind auch EZ von $H$, dazu sind die Eigenenergien $E_{n}=\hbar \omega(n+1/2)$ mit Nullpunktsenergie $E_{0}=\hbar \omega /2$, wobei jede Energie äquidistant zueinander ist. Uns interessiert nun die Ortsdarstellung dieses Problems, um visualisieren zu können, wie die Eigenfunktionen aussehen. Dafür brauchen wir nur das niedrigste (womöglich entartete) $n=0$ zu nehmen, den EV zu bestimmen und daraus die Eigenfunktion. Über die Leiteroperatoren können wir alle anderen bestimmen. 

Dazu hilft uns der Absteigeoperator $a$, da wir für $n=0$ wissen:

$$
a \ket{n=0,i}=\left( \sqrt{ \frac{m\omega}{2\hbar} }\hat{x}+\frac{i}{\sqrt{ 2m\omega \hbar }}\hat{p}\right) \ket{n=0,i}=0 
$$

Für die Ortsdarstellung multiplizieren wir mit $\bra{x}$ von links und erhalten eine lineare DGL 1. Ordnung:

$$
0=\bra{x}a\ket{n=0,i}=\left( \sqrt{ \frac{m\omega}{2\hbar} }x+\frac{i}{\sqrt{ 2m\omega \hbar }} \frac{\hbar}{i} \frac{\text{d}}{\text{d}x}  \right)\underbrace{ \braket{ x | n=0,i }  }_{ =:\varphi_{0}^{i}(x) }
$$

Dabei nutzen wir $\bra{x}\hat{x}=\bra{x}x$ und die Ortsdarstellung von $\hat{p}=-i\hbar\text{ d} /\text{d}x$. Die Gleichung kann man leicht lösen (Side Note: Ich hab VIEL zu lange daran gesessen, mein Gehirn ist so Matsche), und erhält eine eindeutige Lösung (s. HöMa III)

$$
\braket{ x | n=0 } =\varphi_{0}(x)=\left( \frac{m\omega}{\pi \hbar} \right)^{1/4} \exp\left( -\frac{m\omega}{2\hbar}x^{2} \right)
$$

Der Grundzustand ist also nicht entartet, und als Spoiler, sind alle Zustände nicht entartet. Dies zeigen wir induktiv:

Angenommen es existiert ein Zustand $\ket{n}$ wo $\hat{N}\ket{n}=n\ket{n}$, oder genauer $H\ket{n}=\hbar \omega(n+\frac{1}{2})\ket{n}$ gilt (wie wir es oben gezeigt haben). Dann führen wir den Induktionsschritt $n\to n+1$ durch und bilden den EV $\ket{n+1,i}$ zum Eigenwert $n+1$, oder für $H$ auch $\hbar \omega(n+3 /2)$. Wenden wir den Absteigeoperator $a \ket{n+1,i}$ an, so erhalten wir den EV zu $n$ (hier nochmal für $H$; Eigenwert $\hbar \omega(n+1 /2)$). Dieser Vektor ist aber nicht entartet aufgrund unserer Induktionsvorraussetzung, daher gilt $a \ket{n+1,i}=c_{i}\ket{n}$ mit der Konstanten $c_{i}\in \mathbb{C}$. Wenden wir nun den Aufsteigeoperator an, dann erhalten wir

$$
\begin{align}
a^{\dagger}a\ket{n+1,i}&=c_{i}a^{\dagger}\ket{n}=\hat{N}\ket{n+1,i}=(n+1)\ket{n+1,i} \\
\implies \ket{n+1,i}&=\frac{c_{i}}{n+1}a^{\dagger}\ket{n}  
\end{align}
$$

Wir erkennen also, dass jeder Eigenvektor zum EW $n+1$ bzw. $\hbar \omega(n+ 3/2)$ proportional zu $a^{\dagger}\ket{n}$. Sie sind also kolinear, und damit nicht linear unabhängig für beliebige $c_{i}$, weshalb folgt dass jeder Eigenvektor nicht entartet ist. Und das ist gut. Wir haben also auch eine Formel jeden weiteren Eigenzustand ausgehend vom Grundzustand $\ket{0}$ zu basteln:

$$
\ket{n}=c_{n}(a^{\dagger})^{n}\ket{0} = c_{n} a^{\dagger} \frac{1}{c_{n-1}}c_{n-1}(a^{\dagger})^{n-1} \ket{0}=\frac{c_{n}}{c_{n-1}} a^{\dagger}\ket{n-1}  
$$

Wobei wir einfach eine Eins in Form von $c_{n-1} /c_{n-1}=1$ eingefügt haben. Aus unserer Forderung, dass jeder EV normiert ist, bilden wir:

$$
\begin{align}
1=\braket{ n | n } =\frac{\lvert c_{n} \rvert^{2} }{\lvert c_{n-1} \rvert^{2} } \bra{n-1}aa^{\dagger}\ket{n-1}&=  \frac{\lvert c_{n} \rvert^{2} }{\lvert c_{n-1} \rvert^{2} } \bra{n-1}(\hat{N}+\mathbf{1})\ket{n-1} \\
&=\frac{\lvert c_{n} \rvert^{2} }{\lvert c_{n-1} \rvert^{2} }n  
\end{align}
$$

Wir erhalten eine Rekursionsgleichung $\lvert c_{n} \rvert^{2}=\lvert c_{n-1} \rvert^{2} /n$. Wir müssen also wieder nur $\lvert c_{0} \rvert^{2}$ kennen. Dafür nutzen wir die Normierungsbedingung für $\braket{ 1 | 1 }=1$ und $\braket{ 0 | 0 }=1$ aus, als auch die Eigenschaft $\braket{ 1 | 1 }=\bra{1}a^{\dagger}a\ket{1}$, sowie $a\ket{n+1}=c_{n}\ket{n}$, bzw. $a\ket{1}=c_{0}\ket{0}$:

$$
1=\braket{ 1 | 1 }=\bra{1} a^{\dagger}a\ket{1} =c_{0}\bra{1}a^{\dagger}\ket{0}=\lvert c_{0} \rvert^{2} \braket{ 0 | 0 }=\lvert c_{0} \rvert^{2}     
$$

Also ist $\lvert c_{0} \rvert^{2}=1$, und damit $\lvert c_{n} \rvert^{2}= 1/n!$, und wenn $c_{n}$ positiv und reell sein soll, dann können wir jeden Zustand bilden:

$$
\ket{n}=\frac{1}{\sqrt{ n! }} (a^{\dagger})^{n} \ket{0} 
$$

Multiplizieren wir also nun mit $\bra{x}$ von links, um die Ortsdarstellung $\varphi_{n}(x)$ zu erhalten:

$$
\begin{align}
\varphi_{n}(x)&:= \braket{ x | n } \\
&=\left( \frac{m\omega}{\pi \hbar} \right)^{1/4} \frac{1}{\sqrt{ n! }} \left( \frac{1}{\sqrt{ 2 }} \right)^{n} \left( \sqrt{ \frac{m\omega}{\hbar} }x-\frac{1}{\sqrt{ m\omega /\hbar }} \frac{\text{d}}{\text{d}x}  \right)^{n} \exp\left( -\frac{m\omega}{2\hbar }x^{2} \right) \\
&=\left( \frac{m\omega}{\pi \hbar} \right)^{1/4} \frac{1}{\sqrt{ n!2^{n} }} \left( 1-\frac{\text{d}}{\text{d}q}  \right)^{n} \exp\left( -\frac{1}{2}q^{2} \right) 
\end{align}
$$

Dabei haben wir eine Substitution

$$
q:= \sqrt{ \frac{m\omega}{\hbar} }x
$$

genutzt um diesen Ausdruck beinahe in die **Hermitepolynome** $H_{n}$ zu führen, wobei $n\in \mathbb{N}_{0}$ gilt. Sie lassen sich schreiben als

$$
H_{n}(q):=e^{q^{2}/2}\left( 1-\frac{\text{d}}{\text{d}q}  \right)^{n} \exp\left( -\frac{1}{2}q^{2} \right) 
$$

Wir erhalten also jede beliebige Eigenfunktion gemäß

$$
\varphi_{n}(x)=\left( \frac{m\omega}{\pi \hbar} \right)^{1/4} \frac{1}{\sqrt{ n!2^{n} }} e^{-q^{2}/2} H_{n}(q)
$$

Wobei wir, weil wir großzügig sind, die vier niedrigsten Hermitepolynome angeben:

$$
H_{0}(q)=1,\quad H_{1}(q)=2x,\quad H_{2}(q)=4q^{2}-2,\quad H_{3}(q)=8q^{3}-12q
$$

Einige der niedrigsten Lösungen des harmonischen Oszillators in Ortsdarstellung sind unten gezeigt:

![[Pasted image 20250623163628.png]]
Abb.: Eigenfunktionen und Wahrscheinlichkeitsdichten des harmonischen Oszillators

Alle $\ket{n}$ mit $n \in \mathbb{N}_{0}$ sind Eigenvektoren des selbstadjungierten Operators $\hat{N}$ bzw. $H$ wodurch sie eine vollständige Basis auf $\mathcal{L}_{2}(\mathbb{R})$ bilden. Die Eins lässt sich also zerlegen

$$
\mathbf{1}=\sum_{n=0}^{\infty} \ket{n} \bra{n} 
$$

Dies lässt sich auch durch die Hermitepolynome bzw. Ortsdarstellung bestätigen, indem man $\bra{x}$ und $\ket{x'}$ von links bzw. rechts multipliziert. Dann erhält man die Delta-Distribution.

Unter der oberen Zerlegung der Eins können wir $H$ von links multiplizieren, um die Spektraldarstellung des Hamilton-Operators zu erhalten

$$
H=\hbar \omega \sum_{n=0}^{\infty}\left( n+\frac{1}{2} \right)\ket{n} \bra{n} 
$$

Wie man vielleicht schon in den Übungsaufgaben gesehen hat, ist es ein Krampf die Erwartungswerte zu einer gegebenen Energie zu berechnen, da die Hermitepolynome nervige Integrale erstellen. Jedoch müssen wir diese gar nicht anwenden, da wir die Dirac Notation kennen. Wir zeigen dies an dem Orts- und Impulsoperator $\hat{x},\hat{p}$, wobei wir uns die Eigenzustände $\ket{n},\ket{m}$ mit $n,m \in \mathbb{N}_{0}$ anschauen. Der Erwartungswert $\bra{m}\hat{x}\ket{n}$ wird **Übergangsamplitude** genannt, und verrät uns die Wahrscheinlichkeit von Energien $m\to n$ überzugehen. Wir werden sehen, dass