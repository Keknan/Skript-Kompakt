***

Es ist also "Schluss" mit Newton, und wir müssen seine Axiome etwas umschreiben, wenn wir LTs betrachten. Dazu schauen wir uns Rotationen im 3D-Raum an, und die Gleichung

$$
a=b
$$

Diese gilt als invariant unter einer Rotation, wenn sich an der Gleichung nichts ändert. Dies ist z.B. für den Abstand zweier Vektoren der Fall, und gilt allgemein für Skalare. Sie nennen wir **kovariant**. Steht oben $\vec{a}=\vec{b}$ So ändern sich die Werte in der Gleichung nach einer Drehung, sie kann nur kovariant sein, wenn jede Komponente $a_{i}'=b_{i}'$ ist.

Dies können wir in 4D auf **Tensoren** verallgemeinern. Tensoren sind Skalare, Vektoren, Matrizen,... also Gebilde auf die man immer eine Dimension packt. Das gute an Tensoren ist, dass sie sich bei einer Trafo wohldefiniert transformieren, jede Komponente folgt demselben Gesetz. Das geschieht auch bei unserer LT. Wir betrachten Vierertensoren $k$-ter Stufe. die Anzahl der Komponenten des Tensors lässt sich mit $4^{k}$ ermitteln, deswegen nennt man Skalare auch Tensoren $0$-ter Stufe, da dort $4^{0}=1\text{ Komponente}$ gilt.

## 17.1.1 Skalare
***

Ein 4-Skalar, z.B. die Raumzeit $s^{2}$ ist unter einer LT immer invariant, sowie Skalare unter einer 3D Rotation invariant sind.


## 17.1.2 Vierervektoren
***

Wir bezeichnen Vektoren entweder als **kovariant** oder **kontravariant**. Kovariante Vektoren werden mit derselben Transformationsmatrix multipliziert, wie die Basisvektoren. Kontravariante Vektoren wiederum mit der inversen der Transformationsmatrix. Wir markieren kontravariante Vektoren mit einem Supra-Index, und kovariante mit einem klassischen Index:

$$
\begin{align}
a'^{\mu}&=\Lambda_{\mu \lambda}a^{\lambda} & &\text{kontravariant} \\
b'_{\mu}&=\Lambda_{\lambda \mu}^{-1}b_{\lambda}& &\text{kovariant}
\end{align}
$$

Dabei gehen wir direkt auf die LT über. Die LT ist tatsächlich **kein** Tensor, sondern nur eine lineare Transformation, die die Minkowski-Metrik erhalten lassen soll. Dennoch nutzen wir für die LT mit einer alternativen Notation

$$
\Lambda_{\mu \lambda}\equiv \Lambda^{\mu}_{\lambda}
$$

geschrieben. Die Gleichungen werden also zu

$$
\begin{align}
a'^{\mu}&=(\Lambda)^{\mu}_{\lambda}a^{\lambda} \\
b'_{\mu}&=(\Lambda^{-1})^{\lambda}_{\mu}b_{\lambda}
\end{align}
$$

Da uns die zweite Gleichung in der LT noch nicht begegnet ist, ist der 4-Vektor $x^{\mu}=(ct,x,y,z)$ und sein Differential $\text{d}x^{\mu}$ kontravariant. Welcher Vektor wäre denn als Beispiel kovariant? Ein Beispiel ist der 4-Gradient einer Funktion $f$:

$$
\begin{align}
b_{\mu}&=\left( \frac{\partial f}{\partial x^{0}},\frac{\partial f}{\partial x^{1}},\frac{\partial f}{\partial x^{2}},\frac{\partial f}{\partial x^{3}} \right) \\
b'_{\mu}&=\left( \frac{\partial f}{\partial x'^{0}},\frac{\partial f}{\partial x'^{1}},\frac{\partial f}{\partial x'^{2}},\frac{\partial f}{\partial x'^{3}} \right)
\end{align}
$$

^ac2c46

So lassen sich diese beiden Vektoren also tatsächlich über

$$
b_{\mu}'=\frac{\partial f}{\partial x'^{\mu}}=\underbrace{ \frac{\partial f}{\partial x^{\lambda}}  }_{ =b_{\lambda} }\frac{\partial x^{\lambda}}{\partial x'^{\mu}}=\frac{\partial x^{\lambda}}{\partial x'^{\mu}}b_{\lambda}  
$$

Dabei haben wir [[#^ac2c46]] ausgenutzt, nur geben wir diesem Vektor einen anderen Index, was aber völlig gleichgültig ist. Die obere Form in Form einer Multiplikation der Variablenänderung $\partial /\partial x'^{\mu}$ ist die Alternative Form der Tensor Schreibweise.


## 17.1.3 Vierertensor zweiter Stufe
***

Es handelt sich um $n \times n$ Matrizen mit $n=4$, Dabei kann jeder Index kontra-/kovariant sein. Ein 4 Tensor Für Matrizen würde bspw.

$$
F'^{\mu \nu}=\frac{\partial x'^{\mu}}{\partial x^{\alpha}} \frac{\partial x'^{\nu}}{\partial x^{\beta}}F^{\alpha \beta}=\Lambda_{\mu \alpha}\Lambda_{\nu \beta}F^{\alpha \beta}
$$

Dies ist für die LT der Fall, die Lorentz Matrizen erfüllen also

$$
F'^{\mu \nu}=\Lambda_{\alpha}^{\mu}\Lambda_{\beta}^{\nu}F^{\alpha \beta}
$$


## 17.1.3 Das Skalarprodukt und die Metrik
***

Multiplizieren wir einen kovarianten und einen kontravarianten 4 Vektor miteinander, dann erhalten wir 

$$
F_{\nu}^{\mu}=a^{\mu}b_{\nu}
$$

bzw.

$$
F_{\nu}^{\nu}=a^{\nu}b_{\nu}=\sum_{\nu=0}^{3}a^{\nu}b_{\nu}
$$

Wodurch man ein Skalar erhält. Warum steht dann da eine Matrix? Die Spur von $F^{\mu}_{\nu}$ entspricht tatsächlich diesem Skalar Daraus erhalten wir genauso gut ein Ausdruck für die Raumzeit

$$
\text{d}s^{2}=\text{d}x_{\mu}\text{d}x^{\mu}
$$

Nun ist uns aber $\text{d}s^{2}=g_{\alpha \mu}\text{d}x_{\alpha}\text{d}x^{\mu}$ bekannt, Einsetzen lässt also das $\text{d}x^{\mu}$ wegfallen und man erhält

$$
\text{d}x_{\mu}=g_{\alpha \mu}\text{d}x^{\alpha}
$$

Andersrum erhalten wir

$$
\text{d}x^{\mu}=g^{\mu \alpha}\text{d}x_{\alpha}
$$

Und nun können wir beide Gleichungen kombinieren:

$$
\text{d}x^{\mu}=g^{\mu \alpha}\text{d}x_{\alpha}=g^{\mu \alpha}g_{\nu \alpha}\text{d}x^{\alpha}
$$

Dies führt zu einer neuen Formulierung des Kronecker Deltas $\delta_{\nu}^{\mu}$, da wir es mit zwei Tensoren der gleichen Struktur wie $\mathbb{I}$ zutun haben, bzw $g_{\alpha \beta}=g^{\alpha \beta}=g_{\beta \alpha}$

$$
g^{\mu \alpha}g_{\nu \alpha}=\delta_{\nu}^{\mu}=
\begin{cases}
1 & \mu=\nu \\
0&\mu\neq\nu
\end{cases}
$$

Die Minkowski Metrik ist damit ein Tensor, dazu betrachten wir den kovarienten metrischen Tensor unter einer LT:

$$
g_{\alpha \beta}'=\Lambda^{-1}_{\mu \alpha}\Lambda_{\nu \beta}^{-1}g_{\mu \nu}=mbda^{-1}_{\mu \alpha}\Lambda_{\nu \beta}^{-1}\Lambda_{\gamma \mu}\Lambda_{\delta \nu}g_{\gamma\delta}=\delta \alpha \gamma\delta_{\gamma \delta}g_{\gamma\delta}=g_{\alpha \beta}
$$

Der metrische Tensor ändert sich also *nicht*, dies liegt an der Invarianz der Raumzeit. Diese Darstellung hilft uns effizient zwischen kovarianten und kontravarianten Tensoreindizes zu transformieren. Es lässt sich also auch

$$
F_{\nu}^{\mu}=g^{\mu \alpha}F_{\alpha \nu}
$$

